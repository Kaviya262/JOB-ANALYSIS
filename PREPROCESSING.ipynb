{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2b588b5-bfdc-4ff7-8adb-319a88e7fd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Try reading with 'latin1'\n",
    "df = pd.read_csv(\"data_clean.csv\",encoding=\"latin1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be13b726-fbe4-48a3-bac4-9f84eca06ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace(\"'\", \"\").str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31f6f05d-e9a2-447a-bd83-2e698058fd65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title_short</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_schedule_type</th>\n",
       "      <th>job_work_from_home</th>\n",
       "      <th>job_country</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>company_name</th>\n",
       "      <th>S.No</th>\n",
       "      <th>analyst_tools</th>\n",
       "      <th>libraries</th>\n",
       "      <th>cloud</th>\n",
       "      <th>databases</th>\n",
       "      <th>other</th>\n",
       "      <th>programming</th>\n",
       "      <th>webframeworks</th>\n",
       "      <th>os</th>\n",
       "      <th>async</th>\n",
       "      <th>sync</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>San José Province, San José, Costa Rica</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>109500.0</td>\n",
       "      <td>Netskope</td>\n",
       "      <td>1</td>\n",
       "      <td>['excel']</td>\n",
       "      <td>['gdpr']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Arlington, VA</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>Intelletec</td>\n",
       "      <td>2</td>\n",
       "      <td>['tableau']</td>\n",
       "      <td>['spark']</td>\n",
       "      <td>['oracle']</td>\n",
       "      <td>['mongodb', 'mysql', 'mariadb']</td>\n",
       "      <td>['kubernetes']</td>\n",
       "      <td>['mongodb', 'python', 'r', 'sql']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>True</td>\n",
       "      <td>United States</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>Apex Systems</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['sql', 'python']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mountain View, CA</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>228222.0</td>\n",
       "      <td>TikTok</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['sql', 'r', 'python']</td>\n",
       "      <td>['express']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>True</td>\n",
       "      <td>United States</td>\n",
       "      <td>89000.0</td>\n",
       "      <td>Get It Recruit - Transportation</td>\n",
       "      <td>5</td>\n",
       "      <td>['alteryx', 'tableau']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['python', 'r']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  job_title_short                             job_location job_schedule_type  \\\n",
       "0  Data Scientist  San José Province, San José, Costa Rica         Full-time   \n",
       "1   Data Engineer                            Arlington, VA         Full-time   \n",
       "2   Data Engineer                                 Anywhere         Full-time   \n",
       "3  Data Scientist                        Mountain View, CA         Full-time   \n",
       "4    Data Analyst                                 Anywhere         Full-time   \n",
       "\n",
       "   job_work_from_home    job_country  salary_year_avg  \\\n",
       "0               False     Costa Rica         109500.0   \n",
       "1               False          Sudan         140000.0   \n",
       "2                True  United States         120000.0   \n",
       "3               False  United States         228222.0   \n",
       "4                True  United States          89000.0   \n",
       "\n",
       "                      company_name  S.No            analyst_tools   libraries  \\\n",
       "0                         Netskope     1                ['excel']    ['gdpr']   \n",
       "1                       Intelletec     2              ['tableau']   ['spark']   \n",
       "2                     Apex Systems     3                      NaN         NaN   \n",
       "3                           TikTok     4                      NaN         NaN   \n",
       "4  Get It Recruit - Transportation     5   ['alteryx', 'tableau']         NaN   \n",
       "\n",
       "         cloud                         databases            other  \\\n",
       "0          NaN                               NaN              NaN   \n",
       "1   ['oracle']   ['mongodb', 'mysql', 'mariadb']   ['kubernetes']   \n",
       "2          NaN                               NaN              NaN   \n",
       "3          NaN                               NaN              NaN   \n",
       "4          NaN                               NaN              NaN   \n",
       "\n",
       "                          programming webframeworks   os async sync  \n",
       "0                                 NaN           NaN  NaN   NaN  NaN  \n",
       "1   ['mongodb', 'python', 'r', 'sql']           NaN  NaN   NaN  NaN  \n",
       "2                   ['sql', 'python']           NaN  NaN   NaN  NaN  \n",
       "3              ['sql', 'r', 'python']   ['express']  NaN   NaN  NaN  \n",
       "4                     ['python', 'r']           NaN  NaN   NaN  NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9901b0cc-c899-4fae-be4f-f8f2e02d8b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['job_title_short', 'job_location', 'job_schedule_type',\n",
       "       'job_work_from_home', 'job_country', 'salary_year_avg', 'company_name',\n",
       "       'S.No', 'analyst_tools', 'libraries', 'cloud', 'databases', 'other',\n",
       "       'programming', 'webframeworks', 'os', 'async', 'sync'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d14bbc8-d873-4d03-8d92-9b23a8117572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_title_short        object\n",
      "job_location           object\n",
      "job_schedule_type      object\n",
      "job_work_from_home       bool\n",
      "job_country            object\n",
      "salary_year_avg       float64\n",
      "company_name           object\n",
      "S.No                    int64\n",
      "analyst_tools          object\n",
      "libraries              object\n",
      "cloud                  object\n",
      "databases              object\n",
      "other                  object\n",
      "programming            object\n",
      "webframeworks          object\n",
      "os                     object\n",
      "async                  object\n",
      "sync                   object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81b4580-af2f-42de-95f1-04e7692b9fe8",
   "metadata": {},
   "source": [
    "SKILL TO CATEGORY MAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "204ff121-4926-4a99-817b-72feba228dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Actual Column Names: ['job_title_short', 'job_location', 'job_schedule_type', 'job_work_from_home', 'job_country', 'salary_year_avg', 'company_name', 'S.No', 'analyst_tools', 'libraries', 'cloud', 'databases', 'other', 'programming', 'webframeworks', 'os', 'async', 'sync']\n",
      "\n",
      "✅ Skill-to-Category Mapping DataFrame:\n",
      "        Skill       Categories\n",
      "0       excel  [analyst_tools]\n",
      "1     tableau  [analyst_tools]\n",
      "2     alteryx  [analyst_tools]\n",
      "3  powerpoint  [analyst_tools]\n",
      "4    power bi  [analyst_tools]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"data_clean.csv\",encoding=\"latin1\")\n",
    "df.columns = df.columns.str.replace(\"'\", \"\").str.strip()\n",
    "# Ensure column names are clean (remove spaces)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Check actual column names\n",
    "print(\"✅ Actual Column Names:\", df.columns.tolist())\n",
    "\n",
    "# Define skill-related columns\n",
    "list_columns = ['analyst_tools', 'libraries', 'cloud', 'databases', 'other', \n",
    "                'programming', 'webframeworks', 'os', 'async', 'sync']\n",
    "\n",
    "\n",
    "# Convert string representation of lists to actual lists\n",
    "def convert_to_list(value):\n",
    "    if isinstance(value, str):  # If stored as string\n",
    "        try:\n",
    "            result = ast.literal_eval(value)  # Convert string to list\n",
    "            return result if isinstance(result, list) else []  # Ensure list format\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []  # Return empty list if conversion fails\n",
    "    return value if isinstance(value, list) else []  # Keep existing lists\n",
    "\n",
    "# Apply conversion only to existing columns\n",
    "for col in list_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(convert_to_list)\n",
    "\n",
    "# Create skill-to-category mapping\n",
    "skill_to_category = defaultdict(list)\n",
    "\n",
    "for category in list_columns:\n",
    "    if category in df.columns:\n",
    "        for skills in df[category].dropna():\n",
    "            if isinstance(skills, list) and skills:  # Check if valid list\n",
    "                for skill in skills:\n",
    "                    if category not in skill_to_category[skill]:  \n",
    "                        skill_to_category[skill].append(category)\n",
    "\n",
    "# Convert mapping to DataFrame\n",
    "skill_mapping_df = pd.DataFrame(list(skill_to_category.items()), columns=['Skill', 'Categories'])\n",
    "\n",
    "# Display results\n",
    "print(\"\\n✅ Skill-to-Category Mapping DataFrame:\")\n",
    "print(skill_mapping_df.head())\n",
    "\n",
    "# Save the mapping to CSV\n",
    "skill_mapping_df.to_csv(\"skill_mapping.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05df3d07-6b1d-4980-a96f-e79cb9f8cca3",
   "metadata": {},
   "source": [
    "LABEL ENCODDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f501b62a-1966-45a5-af15-a36bd24395b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset processing completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"data_clean.csv\", encoding=\"latin1\")\n",
    "df.columns = df.columns.str.replace(\"'\", \"\").str.strip()\n",
    "\n",
    "# Ensure column names are clean (remove spaces)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Define skill-related columns\n",
    "list_columns = ['analyst_tools', 'libraries', 'cloud', 'databases', 'other', \n",
    "                'programming', 'webframeworks', 'os', 'async', 'sync']\n",
    "\n",
    "# ✅ 1️⃣ Function to clean skill columns properly\n",
    "def clean_list_column(value):\n",
    "    if isinstance(value, str):\n",
    "        try:\n",
    "            cleaned_value = ast.literal_eval(value)  # Convert string to list safely\n",
    "            if isinstance(cleaned_value, list):\n",
    "                return [item.strip() for item in cleaned_value if isinstance(item, str) and len(item) > 0]  \n",
    "            else:\n",
    "                return []\n",
    "        except (SyntaxError, ValueError):\n",
    "            return []  # Return empty list if conversion fails\n",
    "    return value if isinstance(value, list) else []\n",
    "\n",
    "# Apply cleaning function\n",
    "for col in list_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(clean_list_column)\n",
    "\n",
    "# ✅ 2️⃣ Combine all skills into one column\n",
    "df['combined_skills'] = df[list_columns].apply(lambda x: sum(x, []), axis=1)\n",
    "\n",
    "# ✅ 3️⃣ Load & Clean Skill-to-Category Mapping\n",
    "skill_mapping_df = pd.read_csv(\"skill_mapping.csv\")  \n",
    "\n",
    "# Ensure 'Skill' and 'Categories' are correctly formatted\n",
    "skill_mapping_df.dropna(subset=['Skill', 'Categories'], inplace=True)\n",
    "skill_mapping_df['Skill'] = skill_mapping_df['Skill'].str.strip().str.lower()  \n",
    "skill_mapping_df['Categories'] = skill_mapping_df['Categories'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else [])\n",
    "\n",
    "# Convert skill mapping to a dictionary\n",
    "skill_to_category = {skill: categories for skill, categories in zip(skill_mapping_df['Skill'], skill_mapping_df['Categories'])}\n",
    "\n",
    "# ✅ 4️⃣ Function to Map Skills to Categories\n",
    "def map_skills_to_categories(skill_list):\n",
    "    mapped_categories = set()\n",
    "    valid_skills = []\n",
    "    \n",
    "    for skill in skill_list:\n",
    "        skill = skill.strip().lower()  # Standardize skill names\n",
    "        if skill in skill_to_category:  # Only keep valid skills\n",
    "            mapped_categories.update(skill_to_category[skill])  \n",
    "            valid_skills.append(skill)  # Store valid skill\n",
    "\n",
    "    return list(mapped_categories) if mapped_categories else [\"Unknown\"], valid_skills\n",
    "\n",
    "# Apply skill category mapping\n",
    "df[['mapped_skill_categories', 'valid_skills']] = df['combined_skills'].apply(map_skills_to_categories).apply(pd.Series)\n",
    "\n",
    "# ✅ 5️⃣ Convert Skills into Boolean Features\n",
    "all_skills = set(skill_mapping_df['Skill'])  # Ensure all mapped skills are included\n",
    "all_skills.update([\"c\", \"r\"])  # Explicitly add 'c' and 'r' if missing\n",
    "\n",
    "mlb_skills = MultiLabelBinarizer(classes=list(all_skills))  # Set explicit classes\n",
    "df_skills = pd.DataFrame(mlb_skills.fit_transform(df['valid_skills']), columns=mlb_skills.classes_)\n",
    "\n",
    "mlb_categories = MultiLabelBinarizer()\n",
    "df_categories = pd.DataFrame(mlb_categories.fit_transform(df['mapped_skill_categories']), columns=mlb_categories.classes_)\n",
    "\n",
    "# Merge binary features into the dataset\n",
    "df = pd.concat([df.drop(columns=list_columns + ['combined_skills', 'mapped_skill_categories', 'valid_skills']), df_skills, df_categories], axis=1)\n",
    "\n",
    "# ✅ 7️⃣ Apply Label Encoding to Categorical Columns\n",
    "categorical_columns = [\"job_title_short\", \"job_country\", \"company_name\",\"job_schedule_type\",\"job_work_from_home\"]\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))  # Convert to string to avoid NaN issues\n",
    "    label_encoders[col] = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "# ✅ 8️⃣ Save Encoding Mappings\n",
    "with open(\"encoding_mappings.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for col, mapping in label_encoders.items():\n",
    "        f.write(f\"Column: {col}\\n\")\n",
    "        for key, value in mapping.items():\n",
    "            f.write(f\"  '{key}' -> {value}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "# ✅ 9️⃣ Save Processed Dataset\n",
    "df.to_csv(\"processed_data.csv\", index=False)\n",
    "print(\"✅ Dataset processing completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f8bed45-8cb4-46e1-9b31-56c903db6852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Encoding mappings saved as JSON!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "# Load and parse the encoding mappings\n",
    "encoding_mappings = {}\n",
    "\n",
    "with open(\"encoding_mappings.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "current_column = None\n",
    "\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    \n",
    "    # Detect a new column\n",
    "    if line.startswith(\"Column:\"):\n",
    "        current_column = line.split(\":\")[1].strip()\n",
    "        encoding_mappings[current_column] = {}\n",
    "    \n",
    "    # Detect key-value pairs using regex\n",
    "    elif \"->\" in line:\n",
    "        match = re.match(r\"'(.+?)'\\s*->\\s*(\\d+)\", line)\n",
    "        if match:\n",
    "            key, value = match.groups()\n",
    "            encoding_mappings[current_column][key] = int(value)\n",
    "\n",
    "# Save as a proper JSON file\n",
    "with open(\"encoding_mappings.json\", \"w\") as json_file:\n",
    "    json.dump(encoding_mappings, json_file, indent=4)\n",
    "\n",
    "print(\"✅ Encoding mappings saved as JSON!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1e47a6b-b41f-4407-aa9d-3ea371191559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Columns: Index(['job_title_short', 'job_location', 'job_schedule_type',\n",
      "       'job_work_from_home', 'job_country', 'salary_year_avg', 'company_name',\n",
      "       'S.No', 'fortran', 'gatsby',\n",
      "       ...\n",
      "       'airflow', 'sql server', 'flow', 'webex', 'tensorflow', 'clojure',\n",
      "       'couchdb', 'oracle', 'matlab', 'alteryx'],\n",
      "      dtype='object', length=226)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ✅ Load your dataset\n",
    "data = pd.read_csv(\"processed_data.csv\")\n",
    "\n",
    "# ✅ List of 11 columns to drop\n",
    "columns_to_drop = ['analyst_tools', 'async', 'cloud', 'databases', 'libraries', 'os','other', 'programming', 'sync', 'webframeworks']  # Replace with actual column names\n",
    "\n",
    "# ✅ Drop the columns safely\n",
    "data = data.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# ✅ Save the cleaned dataset (optional)\n",
    "data.to_csv(\"cleaned_data.csv\", index=False)\n",
    "\n",
    "# ✅ Verify the changes\n",
    "print(\"Updated Columns:\", data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecf39793-4ee8-43fb-b3b4-b8fab4496ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['excel', 'tableau', 'alteryx', 'powerpoint', 'power bi', 'word', 'visio', 'sharepoint', 'sap', 'microstrategy', 'sas', 'sheets', 'looker', 'spreadsheet', 'dax', 'qlik', 'outlook', 'cognos', 'ssrs', 'ssis', 'spss', 'splunk', 'ms access', 'gdpr', 'spark', 'hadoop', 'kafka', 'pyspark', 'pandas', 'airflow', 'numpy', 'scikit-learn', 'matplotlib', 'plotly', 'ggplot2', 'opencv', 'tensorflow', 'pytorch', 'keras', 'jupyter', 'spring', 'graphql', 'react', 'nltk', 'seaborn', 'oracle', 'aws', 'azure', 'gcp', 'snowflake', 'databricks', 'redshift', 'bigquery', 'aurora', 'ibm cloud', 'mongodb', 'mysql', 'redis', 'dynamodb', 'postgresql', 'sql server', 'neo4j', 'cassandra', 'db2', 'elasticsearch', 'kubernetes', 'terraform', 'git', 'jenkins', 'gitlab', 'github', 'ansible', 'docker', 'flow', 'terminal', 'atlassian', 'bitbucket', 'python', 'r', 'sql', 't-sql', 'golang', 'scala', 'java', 'c', 'nosql', 'go', 'c++', 'shell', 'c#', 'javascript', 'powershell', 'php', 'mongo', 'perl', 'bash', 'vba', 'no-sql', 'julia', 'matlab', 'html', 'assembly', 'css', 'typescript', 'crystal', 'visual basic', 'ruby', 'rust', 'express', 'django', 'flask', 'node.js', 'phoenix', 'angular', 'linux', 'unix', 'windows', 'jira', 'confluence', 'zoom', 'slack', 'unify']\n",
      "Updated CSV file 'processed_data2.csv' has been generated successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"processed_data1.csv\")\n",
    "\n",
    "# List of columns to check for '1' counts\n",
    "columns_to_check = [\n",
    "    \"excel\", \"tableau\", \"alteryx\", \"powerpoint\", \"power bi\", \"word\", \"visio\", \"sharepoint\",\n",
    "    \"sap\", \"microstrategy\", \"sas\", \"sheets\", \"looker\", \"spreadsheet\", \"dax\", \"qlik\",\n",
    "    \"outlook\", \"cognos\", \"ssrs\", \"datarobot\", \"ssis\", \"spss\", \"splunk\", \"ms access\",\n",
    "    \"gdpr\", \"spark\", \"hadoop\", \"electron\", \"kafka\", \"pyspark\", \"pandas\", \"airflow\",\n",
    "    \"selenium\", \"numpy\", \"scikit-learn\", \"matplotlib\", \"plotly\", \"ggplot2\", \"opencv\",\n",
    "    \"tensorflow\", \"pytorch\", \"keras\", \"mxnet\", \"hugging face\", \"jupyter\", \"spring\",\n",
    "    \"graphql\", \"react\", \"tidyverse\", \"xamarin\", \"nltk\", \"seaborn\", \"theano\", \"dplyr\",\n",
    "    \"rshiny\", \"flutter\", \"mlr\", \"qt\", \"cordova\", \"chainer\", \"oracle\", \"aws\", \"azure\",\n",
    "    \"gcp\", \"snowflake\", \"databricks\", \"redshift\", \"bigquery\", \"aurora\", \"vmware\",\n",
    "    \"watson\", \"heroku\", \"ibm cloud\", \"firebase\", \"colocation\", \"openstack\",\n",
    "    \"digitalocean\", \"mongodb\", \"mysql\", \"mariadb\", \"redis\", \"dynamodb\", \"postgresql\",\n",
    "    \"sql server\", \"neo4j\", \"cassandra\", \"db2\", \"elasticsearch\", \"sqlite\", \"couchbase\",\n",
    "    \"firestore\", \"couchdb\", \"kubernetes\", \"terraform\", \"git\", \"jenkins\", \"gitlab\",\n",
    "    \"github\", \"ansible\", \"puppet\", \"docker\", \"flow\", \"yarn\", \"unity\", \"terminal\",\n",
    "    \"atlassian\", \"chef\", \"svn\", \"bitbucket\", \"pulumi\", \"codecommit\", \"unreal\",\n",
    "    \"npm\", \"homebrew\", \"python\", \"r\", \"sql\", \"t-sql\", \"golang\", \"scala\", \"java\",\n",
    "    \"c\", \"nosql\", \"go\", \"c++\", \"shell\", \"c#\", \"javascript\", \"kotlin\", \"powershell\",\n",
    "    \"php\", \"mongo\", \"perl\", \"bash\", \"groovy\", \"vba\", \"no-sql\", \"julia\", \"matlab\",\n",
    "    \"html\", \"assembly\", \"vb.net\", \"css\", \"typescript\", \"crystal\", \"solidity\",\n",
    "    \"visual basic\", \"sass\", \"ruby\", \"erlang\", \"swift\", \"rust\", \"fortran\", \"dart\",\n",
    "    \"elixir\", \"haskell\", \"apl\", \"delphi\", \"cobol\", \"clojure\", \"lisp\", \"objective-c\",\n",
    "    \"pascal\", \"lua\", \"express\", \"django\", \"node\", \"flask\", \"fastapi\", \"node.js\",\n",
    "    \"phoenix\", \"react.js\", \"angular\", \"blazor\", \"jquery\", \"ruby on rails\", \"laravel\",\n",
    "    \"asp.net\", \"next.js\", \"vue.js\", \"svelte\", \"drupal\", \"vue\", \"gatsby\", \"fastify\",\n",
    "    \"asp.net core\", \"angular.js\", \"linux\", \"unix\", \"centos\", \"windows\", \"redhat\",\n",
    "    \"ubuntu\", \"arch\", \"macos\", \"suse\", \"debian\", \"notion\", \"jira\", \"confluence\",\n",
    "    \"smartsheet\", \"asana\", \"monday.com\", \"airtable\", \"workfront\", \"planner\", \"trello\",\n",
    "    \"wrike\", \"clickup\", \"zoom\", \"slack\", \"symphony\", \"unify\", \"microsoft teams\",\n",
    "    \"wire\", \"twilio\", \"ringcentral\", \"webex\"\n",
    "]\n",
    "\n",
    "# Count the number of 1s in each column\n",
    "ones_count = df[columns_to_check].sum()\n",
    "\n",
    "# Filter out columns with less than 50 occurrences of '1'\n",
    "filtered_columns = ones_count[ones_count >= 50].index.tolist()\n",
    "print(filtered_columns)\n",
    "# Required columns to retain\n",
    "required_columns = [\"job_title_short\", \"job_location\", \"job_schedule_type\", \"job_work_from_home\",\n",
    "                    \"job_country\", \"salary_year_avg\", \"company_name\", \"S.No\"]\n",
    "\n",
    "# Create a new DataFrame with filtered and required columns\n",
    "filtered_df = df[filtered_columns + required_columns]\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "filtered_df.to_csv(\"processed_data2.csv\", index=False)\n",
    "\n",
    "print(\"Updated CSV file 'processed_data2.csv' has been generated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234c19bd-9839-4576-ac0f-c7c8dcfd347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'job_title_short', 'job_location', 'job_schedule_type',\n",
    "'job_work_from_home', 'job_country', 'salary_year_avg', 'company_name',\n",
    "'S.No','excel', 'tableau', 'alteryx', 'powerpoint', 'power bi', 'word', 'visio', 'sharepoint',\n",
    "'sap', 'microstrategy', 'sas', 'sheets', 'looker', 'spreadsheet', 'dax', 'qlik', 'outlook', 'cognos', 'ssrs', 'ssis', 'spss', 'splunk', \n",
    "'ms access', 'gdpr', 'spark', 'hadoop', 'kafka', 'pyspark', 'pandas', 'airflow', 'numpy', 'scikit-learn', 'matplotlib', 'plotly', 'ggplot2', 'opencv',\n",
    "'tensorflow', 'pytorch', 'keras', 'jupyter', 'spring', 'graphql', 'react', 'nltk', 'seaborn', 'oracle', 'aws', 'azure', 'gcp', 'snowflake', 'databricks',\n",
    "'redshift', 'bigquery', 'aurora', 'ibm cloud', 'mongodb', 'mysql', 'redis', 'dynamodb', 'postgresql', 'sql server', 'neo4j', 'cassandra', \n",
    "'db2', 'elasticsearch', 'kubernetes', 'terraform', 'git', 'jenkins', 'gitlab', 'github'\n",
    ", 'ansible', 'docker', 'flow', 'terminal', 'atlassian', 'bitbucket', 'python', 'r', 'sql', 't-sql', 'golang', 'scala', 'java', 'c', 'nosql', 'go',\n",
    "'c++', 'shell', 'c#', 'javascript', 'powershell', 'php', 'mongo', 'perl', 'bash', 'vba', 'no-sql', 'julia', 'matlab', 'html', 'assembly',\n",
    "'css', 'typescript', 'crystal', 'visual basic', 'ruby', 'rust', 'express', 'django', 'flask', 'node.js', 'phoenix', 'angular', 'linux', \n",
    "'unix', 'windows', 'jira', 'confluence', 'zoom', 'slack', 'unify'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
