{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a77c977c-bc8b-4442-a136-8f536f54c4c3",
   "metadata": {},
   "source": [
    " DATACLEAN FOR DATASET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1bcdec5-4e1b-4257-8756-5ac43d5a12bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_2700\\847292614.py:4: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  file_path = \"D:\\DOWNLOADS\\8th Sem\\Mini Project\\data_jobs.csv\"\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_2700\\847292614.py:8: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully uploaded!\n",
      "Shape of the dataset: (785741, 18)\n",
      "\n",
      "First 5 rows of the dataset:\n",
      "        job_title_short                                          job_title  \\\n",
      "0  Senior Data Engineer  Senior Clinical Data Engineer / Principal Clin...   \n",
      "1          Data Analyst                                       Data Analyst   \n",
      "2         Data Engineer  Data Engineer/Scientist/Analyst, Mid or Senior...   \n",
      "3         Data Engineer  LEAD ENGINEER - PRINCIPAL ANALYST - PRINCIPAL ...   \n",
      "4         Data Engineer                             Data Engineer- Sr Jobs   \n",
      "\n",
      "                   job_location             job_via job_schedule_type  \\\n",
      "0                 Watertown, CT     via Work Nearby         Full-time   \n",
      "1  Guadalajara, Jalisco, Mexico    via BeBee México         Full-time   \n",
      "2               Berlin, Germany        via LinkedIn         Full-time   \n",
      "3               San Antonio, TX   via Diversity.com         Full-time   \n",
      "4                Washington, DC  via Clearance Jobs         Full-time   \n",
      "\n",
      "   job_work_from_home       search_location   job_posted_date  \\\n",
      "0               False  Texas, United States  16-06-2023 13:44   \n",
      "1               False                Mexico  14-01-2023 13:18   \n",
      "2               False               Germany  10-10-2023 13:14   \n",
      "3               False  Texas, United States  04-07-2023 13:01   \n",
      "4               False                 Sudan  07-08-2023 14:29   \n",
      "\n",
      "   job_no_degree_mention  job_health_insurance    job_country salary_rate  \\\n",
      "0                  False                 False  United States         NaN   \n",
      "1                  False                 False         Mexico         NaN   \n",
      "2                  False                 False        Germany         NaN   \n",
      "3                   True                 False  United States         NaN   \n",
      "4                  False                 False          Sudan         NaN   \n",
      "\n",
      "   salary_year_avg experience_level  salary_hour_avg  \\\n",
      "0              NaN        Mid-level              NaN   \n",
      "1              NaN           Senior              NaN   \n",
      "2              NaN           Senior              NaN   \n",
      "3              NaN           Senior              NaN   \n",
      "4              NaN           Senior              NaN   \n",
      "\n",
      "                   company_name  \\\n",
      "0          Boehringer Ingelheim   \n",
      "1    Hewlett Packard Enterprise   \n",
      "2      ALPHA Augmented Services   \n",
      "3  Southwest Research Institute   \n",
      "4               Kristina Daniel   \n",
      "\n",
      "                                          job_skills  \\\n",
      "0                                                NaN   \n",
      "1  ['r', 'python', 'sql', 'nosql', 'power bi', 't...   \n",
      "2  ['python', 'sql', 'c#', 'azure', 'airflow', 'd...   \n",
      "3  ['python', 'c++', 'java', 'matlab', 'aws', 'te...   \n",
      "4  ['bash', 'python', 'oracle', 'aws', 'ansible',...   \n",
      "\n",
      "                                     job_type_skills  \n",
      "0                                                NaN  \n",
      "1  {'analyst_tools': ['power bi', 'tableau'], 'pr...  \n",
      "2  {'analyst_tools': ['dax'], 'cloud': ['azure'],...  \n",
      "3  {'cloud': ['aws'], 'libraries': ['tensorflow',...  \n",
      "4  {'cloud': ['oracle', 'aws'], 'other': ['ansibl...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'your_dataset.csv' with the path to your dataset file\n",
    "file_path = \"D:\\DOWNLOADS\\8th Sem\\Mini Project\\data_jobs.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"Dataset successfully uploaded!\")\n",
    "    print(f\"Shape of the dataset: {df.shape}\")  # Prints the number of rows and columns\n",
    "    print(\"\\nFirst 5 rows of the dataset:\")\n",
    "    print(df.head())  # Displays the first 5 rows of the dataset\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File not found. Please check the file path.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5dda6be-4643-4d25-a7e4-4e15db68a5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['job_title_short', 'job_title', 'job_location', 'job_via',\n",
       "       'job_schedule_type', 'job_work_from_home', 'search_location',\n",
       "       'job_posted_date', 'job_no_degree_mention', 'job_health_insurance',\n",
       "       'job_country', 'salary_rate', 'salary_year_avg', 'experience_level',\n",
       "       'salary_hour_avg', 'company_name', 'job_skills', 'job_type_skills'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0c0345e-e069-4445-9ae1-3edd687404a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns dropped successfully!\n",
      "Updated shape of the dataset: (785741, 10)\n",
      "\n",
      "First 5 rows of the updated dataset:\n",
      "        job_title_short                  job_location job_schedule_type  \\\n",
      "0  Senior Data Engineer                 Watertown, CT         Full-time   \n",
      "1          Data Analyst  Guadalajara, Jalisco, Mexico         Full-time   \n",
      "2         Data Engineer               Berlin, Germany         Full-time   \n",
      "3         Data Engineer               San Antonio, TX         Full-time   \n",
      "4         Data Engineer                Washington, DC         Full-time   \n",
      "\n",
      "   job_work_from_home    job_country salary_rate  salary_year_avg  \\\n",
      "0               False  United States         NaN              NaN   \n",
      "1               False         Mexico         NaN              NaN   \n",
      "2               False        Germany         NaN              NaN   \n",
      "3               False  United States         NaN              NaN   \n",
      "4               False          Sudan         NaN              NaN   \n",
      "\n",
      "  experience_level                  company_name  \\\n",
      "0        Mid-level          Boehringer Ingelheim   \n",
      "1           Senior    Hewlett Packard Enterprise   \n",
      "2           Senior      ALPHA Augmented Services   \n",
      "3           Senior  Southwest Research Institute   \n",
      "4           Senior               Kristina Daniel   \n",
      "\n",
      "                                     job_type_skills  \n",
      "0                                                NaN  \n",
      "1  {'analyst_tools': ['power bi', 'tableau'], 'pr...  \n",
      "2  {'analyst_tools': ['dax'], 'cloud': ['azure'],...  \n",
      "3  {'cloud': ['aws'], 'libraries': ['tensorflow',...  \n",
      "4  {'cloud': ['oracle', 'aws'], 'other': ['ansibl...  \n"
     ]
    }
   ],
   "source": [
    "# Columns to drop\n",
    "columns_to_drop = [\"job_title\",\"job_via\",\"search_location\",\"job_posted_date\",\"job_no_degree_mention\",\"job_health_insurance\",\"job_skills\",\"salary_hour_avg\"]  # Replace with the names of columns you want to drop\n",
    "\n",
    "# Drop the specified columns\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "print(\"Columns dropped successfully!\")\n",
    "print(f\"Updated shape of the dataset: {df.shape}\")\n",
    "print(\"\\nFirst 5 rows of the updated dataset:\")\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fa23644-e0ec-40a3-9521-2a4dbf1be3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values found in the dataset:\n",
      "job_location           1045\n",
      "job_schedule_type     12667\n",
      "job_country              49\n",
      "salary_rate          752674\n",
      "salary_year_avg      763738\n",
      "experience_level     776386\n",
      "company_name             18\n",
      "job_type_skills      117037\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Print columns with missing values and their counts\n",
    "if missing_values.any():\n",
    "    print(\"Missing values found in the dataset:\")\n",
    "    print(missing_values[missing_values > 0])\n",
    "else:\n",
    "    print(\"No missing values found in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec2c03e0-2c6c-4d8d-8956-01ebeba3ff23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values after removing rows:\n",
      "job_title_short       0\n",
      "job_location          0\n",
      "job_schedule_type     0\n",
      "job_work_from_home    0\n",
      "job_country           0\n",
      "salary_rate           0\n",
      "salary_year_avg       0\n",
      "experience_level      0\n",
      "company_name          0\n",
      "job_type_skills       0\n",
      "dtype: int64\n",
      "\n",
      "Original dataset shape: (785741, 10)\n",
      "Cleaned dataset shape: (301, 10)\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Check if all missing values are removed\n",
    "print(\"\\nMissing values after removing rows:\")\n",
    "print(df_cleaned.isnull().sum())\n",
    "\n",
    "# Display the shape of the cleaned dataset\n",
    "print(f\"\\nOriginal dataset shape: {df.shape}\")\n",
    "print(f\"Cleaned dataset shape: {df_cleaned.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6374010-a3ee-4eeb-afca-9b4036a487b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          job_title_short                             job_location  \\\n",
      "28         Data Scientist  San José Province, San José, Costa Rica   \n",
      "77          Data Engineer                            Arlington, VA   \n",
      "92          Data Engineer                                 Anywhere   \n",
      "100        Data Scientist                        Mountain View, CA   \n",
      "109          Data Analyst                                 Anywhere   \n",
      "...                   ...                                      ...   \n",
      "9255       Data Scientist                             Westlake, TX   \n",
      "9314        Data Engineer                           Plantation, FL   \n",
      "9329  Senior Data Analyst                                 Anywhere   \n",
      "9340        Data Engineer                 New York, NY (+3 others)   \n",
      "9344         Data Analyst                                 Anywhere   \n",
      "\n",
      "     job_schedule_type  job_work_from_home    job_country salary_rate  \\\n",
      "28           Full-time               False     Costa Rica        year   \n",
      "77           Full-time               False          Sudan        year   \n",
      "92           Full-time                True  United States        year   \n",
      "100          Full-time               False  United States        year   \n",
      "109          Full-time                True  United States        year   \n",
      "...                ...                 ...            ...         ...   \n",
      "9255         Full-time               False  United States        year   \n",
      "9314         Full-time               False  United States        year   \n",
      "9329         Full-time                True  United States        year   \n",
      "9340         Full-time               False  United States        year   \n",
      "9344         Full-time                True  United States        year   \n",
      "\n",
      "      salary_year_avg experience_level  \\\n",
      "28           109500.0        Mid-level   \n",
      "77           140000.0        Mid-level   \n",
      "92           120000.0        Mid-level   \n",
      "100          228222.0           Senior   \n",
      "109           89000.0           Senior   \n",
      "...               ...              ...   \n",
      "9255         111000.0      Entry-level   \n",
      "9314         135000.0        Mid-level   \n",
      "9329         126000.0           Senior   \n",
      "9340         215000.0        Mid-level   \n",
      "9344          83000.0        Mid-level   \n",
      "\n",
      "                                           company_name  \\\n",
      "28                                             Netskope   \n",
      "77                                           Intelletec   \n",
      "92                                         Apex Systems   \n",
      "100                                              TikTok   \n",
      "109                     Get It Recruit - Transportation   \n",
      "...                                                 ...   \n",
      "9255                                          Robinhood   \n",
      "9314                                        Robert Half   \n",
      "9329                                   Cityblock Health   \n",
      "9340                                            Datadog   \n",
      "9344  Alameda Health Consortium/Community Health Cen...   \n",
      "\n",
      "                                        job_type_skills  \n",
      "28    {'analyst_tools': ['excel'], 'libraries': ['gd...  \n",
      "77    {'analyst_tools': ['tableau'], 'cloud': ['orac...  \n",
      "92                   {'programming': ['sql', 'python']}  \n",
      "100   {'programming': ['sql', 'r', 'python'], 'webfr...  \n",
      "109   {'analyst_tools': ['alteryx', 'tableau'], 'pro...  \n",
      "...                                                 ...  \n",
      "9255  {'analyst_tools': ['looker', 'tableau'], 'prog...  \n",
      "9314  {'analyst_tools': ['power bi'], 'async': ['jir...  \n",
      "9329  {'analyst_tools': ['looker', 'tableau'], 'clou...  \n",
      "9340  {'libraries': ['spark'], 'programming': ['scal...  \n",
      "9344  {'analyst_tools': ['sas', 'excel', 'tableau'],...  \n",
      "\n",
      "[282 rows x 10 columns]\n",
      "\n",
      "Original dataset shape: (301, 10)\n",
      "Cleaned dataset shape: (282, 10)\n"
     ]
    }
   ],
   "source": [
    "df_cleaned1= df_cleaned.drop_duplicates(subset=['job_title_short', 'job_location', 'job_country','company_name'], keep='first')\n",
    "print(df_cleaned1)\n",
    "print(f\"\\nOriginal dataset shape: {df_cleaned.shape}\")\n",
    "print(f\"Cleaned dataset shape: {df_cleaned1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0400605-04b0-4b5c-ab61-44b64cc8db74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved as 'D:\\DOWNLOADS\\8th Sem\\Mini Project\\DATA_CLEAN1.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_2700\\2977953370.py:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  output_file = \"D:\\DOWNLOADS\\8th Sem\\Mini Project\\DATA_CLEAN1.csv\"\n"
     ]
    }
   ],
   "source": [
    "output_file = \"D:\\DOWNLOADS\\8th Sem\\Mini Project\\DATA_CLEAN1.csv\"\n",
    "df_cleaned1.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Cleaned dataset saved as '{output_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78867fa-4818-4c77-a7be-8a20e8d90160",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
